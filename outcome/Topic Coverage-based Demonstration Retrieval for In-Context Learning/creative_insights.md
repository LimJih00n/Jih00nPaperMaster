# Topic Coverage-based Demonstration Retrieval for In-Context Learning - ì°½ì˜ì  í™•ì¥ ë° ì‘ìš©

## ğŸ’¡ ì°½ì˜ì  í™•ì¥ ì•„ì´ë””ì–´

### ğŸ”® 1. ì°¨ì„¸ëŒ€ ë°œì „ ë°©í–¥

#### ê³„ì¸µì  í† í”½ êµ¬ì¡° (Hierarchical Topic Structure)
```python
# í˜„ì¬: Flat Topic Set
topics = ["herbivore", "carnivore", "omnivore", "plant", "ecosystem"]

# ì œì•ˆ: ê³„ì¸µì  í† í”½ êµ¬ì¡°
hierarchical_topics = {
    "biology": {
        "ecology": {
            "feeding_behavior": ["herbivore", "carnivore", "omnivore"],
            "ecosystem": ["food_chain", "food_web", "trophic_level"]
        },
        "organisms": {
            "animals": ["vertebrate", "invertebrate", "mammal"],
            "plants": ["flowering", "non_flowering", "photosynthesis"]
        }
    }
}

# ì¥ì : ë” ì •êµí•œ í† í”½ ê´€ê³„ íŒŒì•…, ì¶”ìƒí™” ìˆ˜ì¤€ ì¡°ì ˆ ê°€ëŠ¥
# êµ¬í˜„: Tree-LSTM, Graph Neural Networks í™œìš©
```

#### ë™ì  í† í”½ ë°œê²¬ (Dynamic Topic Discovery)
```python
# í˜„ì¬: ì‚¬ì „ ì •ì˜ëœ í† í”½ ì„¸íŠ¸
# ë¬¸ì œ: ìƒˆë¡œìš´ ë„ë©”ì¸/ë°ì´í„°ì…‹ë§ˆë‹¤ ì¬êµ¬ì„± í•„ìš”

# ì œì•ˆ: ì‹¤ì‹œê°„ í† í”½ ë°œê²¬
class DynamicTopicDiscovery:
    def __init__(self):
        self.topic_embeddings = {}
        self.topic_evolution = []
        
    def discover_new_topics(self, new_demonstrations):
        # 1. í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ìƒˆë¡œìš´ í† í”½ í›„ë³´ ë°œê²¬
        # 2. ê¸°ì¡´ í† í”½ê³¼ì˜ ìœ ì‚¬ì„± ê²€ì¦
        # 3. í† í”½ ì¤‘ìš”ë„ í‰ê°€ í›„ ì¶”ê°€/ì œê±°
        pass
        
    def evolve_topics(self, feedback_signal):
        # ì„±ëŠ¥ í”¼ë“œë°± ê¸°ë°˜ í† í”½ êµ¬ì¡° ì§„í™”
        pass

# ì ìš© ë¶„ì•¼: ì§€ì†ì  í•™ìŠµ, ë„ë©”ì¸ ì ì‘
```

#### ë‹¤ì¤‘ ëª¨ë‹¬ í† í”½ ëª¨ë¸ë§ (Multi-modal Topic Modeling)
```python
# í˜„ì¬: í…ìŠ¤íŠ¸ë§Œ í™œìš©
# í™•ì¥: ì´ë¯¸ì§€, ì˜¤ë””ì˜¤, ë¹„ë””ì˜¤ ë“± ë‹¤ì¤‘ ëª¨ë‹¬

class MultiModalTopicK:
    def __init__(self):
        self.text_encoder = SentenceTransformer()
        self.image_encoder = CLIPVisionModel()
        self.audio_encoder = Wav2Vec2Model()
        
    def extract_multimodal_topics(self, demonstration):
        text_topics = self.extract_text_topics(demonstration.text)
        
        if demonstration.has_image:
            image_topics = self.extract_image_topics(demonstration.image)
            # "visual_herbivore", "green_plants", "grazing_behavior"
            
        if demonstration.has_audio:
            audio_topics = self.extract_audio_topics(demonstration.audio)
            # "animal_sounds", "chewing_noise", "natural_environment"
            
        # ë‹¤ì¤‘ ëª¨ë‹¬ ì •ë³´ ìœµí•©
        fused_topics = self.fuse_modal_topics(text_topics, image_topics, audio_topics)
        return fused_topics

# ì‘ìš©: êµìœ¡ ì½˜í…ì¸ , ì˜ë£Œ ì§„ë‹¨, ë©€í‹°ë¯¸ë””ì–´ QA
```

### ğŸ¯ 2. ë„ë©”ì¸ë³„ íŠ¹í™” ì‘ìš©

#### ì˜ë£Œ ë„ë©”ì¸: ì¦ìƒ-ì§ˆë³‘ í† í”½ ë§¤í•‘
```python
# ì˜ë£Œ íŠ¹í™” TopicK
class MedicalTopicK(TopicK):
    def __init__(self):
        super().__init__()
        self.symptom_ontology = load_medical_ontology()
        self.disease_hierarchy = load_disease_taxonomy()
        
    def extract_medical_topics(self, case_description):
        # 1. ì¦ìƒ ì¶”ì¶œ: "fever", "cough", "shortness_of_breath"
        symptoms = self.extract_symptoms(case_description)
        
        # 2. í•´ë¶€í•™ì  ë¶€ìœ„: "respiratory_system", "cardiovascular"
        anatomy = self.extract_anatomy(case_description)
        
        # 3. ì§ˆë³‘ ì¹´í…Œê³ ë¦¬: "infectious_disease", "chronic_condition"
        disease_categories = self.predict_disease_categories(symptoms, anatomy)
        
        return {
            "symptoms": symptoms,
            "anatomy": anatomy, 
            "disease_categories": disease_categories,
            "severity": self.assess_severity(symptoms)
        }

# ì¼€ì´ìŠ¤ ì˜ˆì‹œ
test_case = "65ì„¸ ë‚¨ì„±, 3ì¼ê°„ ì§€ì†ëœ ë°œì—´ê³¼ ê¸°ì¹¨, í˜¸í¡ê³¤ë€ í˜¸ì†Œ"
medical_topics = {
    "symptoms": ["fever", "cough", "dyspnea"],
    "demographics": ["elderly", "male"],
    "duration": ["acute_onset"],
    "system": ["respiratory"],
    "differential_dx": ["pneumonia", "covid19", "copd_exacerbation"]
}

# ëª¨ë¸ì´ íë ´ ê´€ë ¨ ì§€ì‹ì´ ë¶€ì¡±í•˜ë©´ -> íë ´ ì¼€ì´ìŠ¤ ìš°ì„  ì„ íƒ
```

#### ë²•ë¬´ ë„ë©”ì¸: íŒë¡€-ë²•ì¡°ë¬¸ í† í”½ ì—°ê²°
```python
class LegalTopicK(TopicK):
    def __init__(self):
        super().__init__()
        self.legal_codes = load_legal_codes()  # ë¯¼ë²•, í˜•ë²•, ìƒë²• ë“±
        self.case_law_db = load_case_law_database()
        
    def extract_legal_topics(self, legal_query):
        # 1. ë²•ì  ìŸì : "contract_breach", "tort_liability", "criminal_intent"
        legal_issues = self.identify_legal_issues(legal_query)
        
        # 2. ê´€ë ¨ ë²•ì¡°ë¬¸: "ë¯¼ë²• ì œ750ì¡°", "í˜•ë²• ì œ13ì¡°"
        relevant_statutes = self.match_statutes(legal_issues)
        
        # 3. íŒë¡€ íŒ¨í„´: "ëŒ€ë²•ì› 2020ë‹¤12345", "í—Œë²•ì¬íŒì†Œ 2019í—Œë§ˆ123"
        case_precedents = self.find_precedents(legal_issues)
        
        return {
            "legal_domain": self.classify_domain(legal_query),  # ë¯¼ì‚¬, í˜•ì‚¬, í–‰ì •
            "legal_issues": legal_issues,
            "statutes": relevant_statutes,
            "precedents": case_precedents,
            "jurisdiction": self.determine_jurisdiction(legal_query)
        }

# ì˜ˆì‹œ: ê³„ì•½ ìœ„ë°˜ ì†Œì†¡
query = "ì„ëŒ€ì°¨ ê³„ì•½ì—ì„œ ì„ì°¨ì¸ì´ ì›”ì„¸ë¥¼ 3ê°œì›”ê°„ ì—°ì²´í•œ ê²½ìš°"
legal_topics = {
    "domain": "civil_law",
    "contract_type": "lease_agreement", 
    "breach_type": "payment_default",
    "remedies": ["termination", "eviction", "damages"],
    "statutes": ["ë¯¼ë²•_ì œ618ì¡°", "ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•_ì œ10ì¡°"]
}
```

#### êµìœ¡ ë„ë©”ì¸: í•™ìŠµ ë‚œì´ë„ë³„ í† í”½ ê³„ì¸µí™”
```python
class EducationalTopicK(TopicK):
    def __init__(self):
        super().__init__()
        self.curriculum_standards = load_curriculum_database()
        self.difficulty_classifier = load_difficulty_model()
        
    def extract_educational_topics(self, learning_material):
        # 1. ê³¼ëª© ë¶„ë¥˜: "mathematics", "physics", "chemistry", "biology"
        subject = self.classify_subject(learning_material)
        
        # 2. í•™ìŠµ ìˆ˜ì¤€: "elementary", "middle", "high", "college"
        difficulty_level = self.assess_difficulty(learning_material)
        
        # 3. ê°œë… ê³„ì¸µ: "basic_concept", "intermediate_application", "advanced_synthesis"
        concept_hierarchy = self.map_concept_hierarchy(learning_material)
        
        # 4. ì „ì œ ì§€ì‹: ["algebra", "geometry"] -> ["calculus"]
        prerequisites = self.identify_prerequisites(learning_material)
        
        return {
            "subject": subject,
            "difficulty": difficulty_level,
            "concepts": concept_hierarchy,
            "prerequisites": prerequisites,
            "learning_objectives": self.extract_objectives(learning_material)
        }

# ì ì‘í˜• í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤
student_profile = {
    "current_level": "algebra_intermediate",
    "weak_areas": ["quadratic_equations", "factoring"],
    "strong_areas": ["linear_equations", "basic_operations"]
}

# TopicKê°€ ì•½í•œ ì˜ì—­ ê´€ë ¨ ì˜ˆì œë¥¼ ìš°ì„  ì„ íƒ
# -> ê°œì¸í™”ëœ í•™ìŠµ ê²½ë¡œ ìƒì„±
```

### ğŸš€ 3. ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ ì œì•ˆ

#### Meta-TopicK: í† í”½ ëª¨ë¸ì˜ í† í”½ ëª¨ë¸
```python
class MetaTopicK:
    """ì—¬ëŸ¬ ë„ë©”ì¸ì˜ TopicKë¥¼ í†µí•© ê´€ë¦¬í•˜ëŠ” ë©”íƒ€ ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.domain_specialists = {
            "medical": MedicalTopicK(),
            "legal": LegalTopicK(), 
            "educational": EducationalTopicK(),
            "general": TopicK()
        }
        self.domain_router = DomainClassifier()
        self.cross_domain_mapper = CrossDomainTopicMapper()
        
    def route_and_retrieve(self, query, demonstration_pool):
        # 1. ë„ë©”ì¸ ë¶„ë¥˜
        primary_domain = self.domain_router.classify(query)
        secondary_domains = self.domain_router.get_related_domains(primary_domain)
        
        # 2. ë„ë©”ì¸ë³„ TopicK ì‹¤í–‰
        primary_results = self.domain_specialists[primary_domain].retrieve(
            query, demonstration_pool
        )
        
        # 3. í¬ë¡œìŠ¤ ë„ë©”ì¸ ì •ë³´ ìœµí•©
        if secondary_domains:
            secondary_results = []
            for domain in secondary_domains:
                result = self.domain_specialists[domain].retrieve(
                    query, demonstration_pool
                )
                secondary_results.append(result)
            
            # ë„ë©”ì¸ ê°„ í† í”½ ë§¤í•‘ ë° ìœµí•©
            fused_results = self.cross_domain_mapper.fuse(
                primary_results, secondary_results
            )
            return fused_results
        
        return primary_results

# ì˜ˆì‹œ: ì˜ë£Œ-ë²•ë¬´ ìœµí•© ì¼€ì´ìŠ¤
query = "ì˜ë£Œì§„ì˜ ì„¤ëª…ì˜ë¬´ ìœ„ë°˜ìœ¼ë¡œ ì¸í•œ ì†í•´ë°°ìƒ ì²­êµ¬"
# -> ì˜ë£Œ ë„ë©”ì¸ (ì„¤ëª…ì˜ë¬´, ì˜ë£Œê³¼ì‹¤) + ë²•ë¬´ ë„ë©”ì¸ (ì†í•´ë°°ìƒ, ê³¼ì‹¤ì±…ì„)
```

#### Temporal-TopicK: ì‹œê°„ íë¦„ì„ ê³ ë ¤í•œ í† í”½ ëª¨ë¸ë§
```python
class TemporalTopicK(TopicK):
    """ì‹œê°„ì  ë³€í™”ë¥¼ ê³ ë ¤í•œ í† í”½ ì„ íƒ"""
    
    def __init__(self):
        super().__init__()
        self.temporal_encoder = TemporalTransformer()
        self.trend_analyzer = TopicTrendAnalyzer()
        
    def extract_temporal_topics(self, query, timestamp):
        # 1. ì‹œê°„ ì˜ì¡´ì  í† í”½ ì¶”ì¶œ
        seasonal_topics = self.extract_seasonal_patterns(query, timestamp)
        # ì˜ˆ: "flu_season" (ê²¨ìš¸), "allergy" (ë´„), "heat_stroke" (ì—¬ë¦„)
        
        # 2. íŠ¸ë Œë“œ í† í”½ ë°˜ì˜
        trending_topics = self.trend_analyzer.get_trending_topics(timestamp)
        # ì˜ˆ: "covid19_variant", "climate_change", "ai_regulation"
        
        # 3. ì—­ì‚¬ì  ë§¥ë½ ê³ ë ¤
        historical_context = self.get_historical_context(query, timestamp)
        
        return {
            "static_topics": self.extract_topics(query),
            "temporal_topics": seasonal_topics,
            "trending_topics": trending_topics,
            "historical_context": historical_context
        }
    
    def temporal_relevance_score(self, query, demo, current_time):
        base_score = super().relevance_score(query, demo)
        
        # ì‹œê°„ì  ê´€ë ¨ì„± ê°€ì¤‘ì¹˜
        temporal_weight = self.calculate_temporal_relevance(
            demo.timestamp, current_time, demo.topics
        )
        
        return base_score * temporal_weight

# ì‘ìš©: ë‰´ìŠ¤ ì¶”ì²œ, íŠ¸ë Œë“œ ë¶„ì„, ì—­ì‚¬ ì—°êµ¬
```

### ğŸ”§ 4. ê¸°ìˆ ì  í˜ì‹  ì•„ì´ë””ì–´

#### Adversarial Topic Robustness
```python
class RobustTopicK(TopicK):
    """ì ëŒ€ì  ê³µê²©ì— ê°•ê±´í•œ í† í”½ ëª¨ë¸ë§"""
    
    def __init__(self):
        super().__init__()
        self.adversarial_detector = AdversarialDetector()
        self.topic_validator = TopicConsistencyValidator()
        
    def robust_topic_extraction(self, text):
        # 1. ì ëŒ€ì  ì…ë ¥ íƒì§€
        is_adversarial = self.adversarial_detector.detect(text)
        
        if is_adversarial:
            # ì ëŒ€ì  ë…¸ì´ì¦ˆ ì œê±°
            cleaned_text = self.remove_adversarial_noise(text)
            topics = self.extract_topics(cleaned_text)
        else:
            topics = self.extract_topics(text)
        
        # 2. í† í”½ ì¼ê´€ì„± ê²€ì¦
        validated_topics = self.topic_validator.validate(topics, text)
        
        return validated_topics
    
    def consensus_topic_selection(self, query, demonstration_pool):
        """ì—¬ëŸ¬ í† í”½ ì¶”ì¶œê¸°ì˜ í•©ì˜ë¥¼ í†µí•œ ê°•ê±´í•œ ì„ íƒ"""
        topic_extractors = [
            self.base_extractor,
            self.robust_extractor_1, 
            self.robust_extractor_2
        ]
        
        topic_votes = []
        for extractor in topic_extractors:
            topics = extractor.extract_topics(query)
            topic_votes.append(topics)
        
        # íˆ¬í‘œ ê¸°ë°˜ í† í”½ í•©ì˜
        consensus_topics = self.voting_mechanism(topic_votes)
        return self.retrieve_with_topics(consensus_topics, demonstration_pool)

# ì ìš©: ê¸ˆìœµ, ì˜ë£Œ, ë²•ë¬´ ë“± ê³ ì‹ ë¢°ì„± ìš”êµ¬ ë„ë©”ì¸
```

#### Few-shot Topic Learning
```python
class FewShotTopicK(TopicK):
    """ì ì€ ë°ì´í„°ë¡œë„ ìƒˆë¡œìš´ ë„ë©”ì¸ì— ë¹ ë¥´ê²Œ ì ì‘"""
    
    def __init__(self):
        super().__init__()
        self.meta_learner = MAML()  # Model-Agnostic Meta-Learning
        self.prototype_network = PrototypicalNetwork()
        
    def quick_domain_adaptation(self, few_examples, domain_name):
        # 1. Few-shotìœ¼ë¡œ ë„ë©”ì¸ íŠ¹í™” í† í”½ ë°œê²¬
        domain_prototypes = self.prototype_network.learn_prototypes(few_examples)
        
        # 2. ë©”íƒ€ í•™ìŠµìœ¼ë¡œ ë¹ ë¥¸ ì ì‘
        adapted_model = self.meta_learner.adapt(
            self.base_model, few_examples, domain_prototypes
        )
        
        # 3. ë„ë©”ì¸ë³„ í† í”½ ì„ë² ë”© í•™ìŠµ
        domain_topic_embeddings = self.learn_domain_embeddings(
            few_examples, domain_prototypes
        )
        
        return adapted_model, domain_topic_embeddings
    
    def cross_lingual_topic_transfer(self, source_lang, target_lang):
        """ì–¸ì–´ ê°„ í† í”½ ì§€ì‹ ì „ì´"""
        # ë‹¤êµ­ì–´ ì„ë² ë”© ê³µê°„ì—ì„œ í† í”½ ë§¤í•‘
        topic_mapping = self.align_cross_lingual_topics(source_lang, target_lang)
        return topic_mapping

# ì‘ìš©: ë‹¤êµ­ì–´ ì§€ì›, ì‹ ê·œ ë„ë©”ì¸ ë¹ ë¥¸ ë°°í¬, ë¦¬ì†ŒìŠ¤ ì œì•½ í™˜ê²½
```

### ğŸŒ 5. ì‹¤ë¬´ ì ìš© í™•ì¥

#### ê¸°ì—… ì§€ì‹ ê´€ë¦¬ ì‹œìŠ¤í…œ
```python
class CorporateTopicK(TopicK):
    """ê¸°ì—… ë‚´ë¶€ ì§€ì‹ ê´€ë¦¬ë¥¼ ìœ„í•œ íŠ¹í™” ì‹œìŠ¤í…œ"""
    
    def __init__(self, company_context):
        super().__init__()
        self.company_ontology = company_context.knowledge_graph
        self.department_specialization = company_context.dept_topics
        self.security_classifier = SecurityLevelClassifier()
        
    def corporate_knowledge_retrieval(self, employee_query):
        # 1. ë³´ì•ˆ ìˆ˜ì¤€ ë¶„ë¥˜
        security_level = self.security_classifier.classify(employee_query)
        accessible_docs = self.filter_by_security(security_level)
        
        # 2. ë¶€ì„œë³„ ì „ë¬¸ì„± ê³ ë ¤
        user_dept = self.get_user_department(employee_query.user_id)
        dept_topics = self.department_specialization[user_dept]
        
        # 3. ê¸°ì—… íŠ¹í™” í† í”½ ì¶”ì¶œ
        company_topics = self.extract_corporate_topics(employee_query.text)
        # ì˜ˆ: "quarterly_planning", "client_relationship", "product_roadmap"
        
        # 4. ì»¨í…ìŠ¤íŠ¸ ì¸ì‹ ê²€ìƒ‰
        relevant_docs = self.retrieve_with_context(
            company_topics, accessible_docs, dept_topics
        )
        
        return relevant_docs

# ê¸°ëŠ¥:
# - ë³´ì•ˆ ë“±ê¸‰ë³„ ë¬¸ì„œ ì ‘ê·¼ ì œì–´
# - ë¶€ì„œë³„ ì „ë¬¸ ì§€ì‹ ìš°ì„  ì œê³µ
# - ê¸°ì—… ê³ ìœ  ìš©ì–´/í”„ë¡œì„¸ìŠ¤ í•™ìŠµ
# - í”„ë¡œì íŠ¸ ë‹¨ìœ„ ì§€ì‹ ê´€ë¦¬
```

#### ê°œì¸í™”ëœ í•™ìŠµ ì–´ì‹œìŠ¤í„´íŠ¸
```python
class PersonalizedLearningTopicK(TopicK):
    """ê°œì¸ í•™ìŠµ íŒ¨í„´ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ë°ëª¨ ì„ íƒ"""
    
    def __init__(self):
        super().__init__()
        self.learning_style_classifier = LearningStyleClassifier()
        self.knowledge_tracer = BayesianKnowledgeTracing()
        self.difficulty_calibrator = DifficultyCalibrator()
        
    def personalized_demonstration_selection(self, student_id, learning_query):
        # 1. í•™ìŠµ ìŠ¤íƒ€ì¼ ë¶„ì„
        learning_style = self.learning_style_classifier.predict(student_id)
        # "visual_learner", "auditory_learner", "kinesthetic_learner"
        
        # 2. ì§€ì‹ ìƒíƒœ ì¶”ì •
        knowledge_state = self.knowledge_tracer.estimate_knowledge(
            student_id, learning_query.topic
        )
        
        # 3. ì ì‘í˜• ë‚œì´ë„ ì¡°ì ˆ
        optimal_difficulty = self.difficulty_calibrator.calibrate(
            knowledge_state, learning_style, learning_query.target_performance
        )
        
        # 4. ê°œì¸í™”ëœ í† í”½ ê°€ì¤‘ì¹˜
        personal_topic_weights = self.compute_personal_weights(
            learning_style, knowledge_state, learning_query.topics
        )
        
        # 5. ë§ì¶¤í˜• ë°ëª¨ ì„ íƒ
        personalized_demos = self.select_demonstrations(
            learning_query, optimal_difficulty, personal_topic_weights
        )
        
        return personalized_demos
    
    def adaptive_feedback_loop(self, student_id, selected_demos, performance):
        """í•™ìŠµ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í† í”½ ëª¨ë¸ ê°œì„ """
        # ì„±ê³µ/ì‹¤íŒ¨ íŒ¨í„´ í•™ìŠµ
        self.knowledge_tracer.update(student_id, selected_demos, performance)
        
        # í† í”½ ì„ íƒ ì „ëµ ì—…ë°ì´íŠ¸
        self.update_topic_selection_policy(student_id, selected_demos, performance)

# ì ìš© íš¨ê³¼:
# - í•™ìŠµ íš¨ìœ¨ì„± ê·¹ëŒ€í™”
# - ê°œì¸ë³„ ì•½ì  ì§‘ì¤‘ ë³´ì™„
# - í•™ìŠµ ë™ê¸° ì¦ì§„
# - ì¸ì§€ ë¶€í•˜ ìµœì í™”
```

### ğŸ“Š 6. ì„±ëŠ¥ í–¥ìƒ ì „ëµ

#### Ensemble TopicK
```python
class EnsembleTopicK:
    """ì—¬ëŸ¬ TopicK ë³€í˜•ë“¤ì˜ ì•™ìƒë¸”ë¡œ ì„±ëŠ¥ ê·¹ëŒ€í™”"""
    
    def __init__(self):
        self.topic_models = [
            HierarchicalTopicK(),
            TemporalTopicK(), 
            MultiModalTopicK(),
            DomainSpecificTopicK(),
            RobustTopicK()
        ]
        self.ensemble_weights = self.learn_ensemble_weights()
        self.diversity_controller = DiversityController()
        
    def ensemble_demonstration_selection(self, query, demo_pool):
        model_predictions = []
        
        # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ ìˆ˜ì§‘
        for model in self.topic_models:
            demos = model.select_demonstrations(query, demo_pool)
            confidence = model.compute_confidence(query, demos)
            model_predictions.append((demos, confidence))
        
        # ë‹¤ì–‘ì„± ê³ ë ¤í•œ ì•™ìƒë¸”
        diverse_predictions = self.diversity_controller.ensure_diversity(
            model_predictions
        )
        
        # ê°€ì¤‘ íˆ¬í‘œë¡œ ìµœì¢… ì„ íƒ
        final_demos = self.weighted_ensemble(
            diverse_predictions, self.ensemble_weights
        )
        
        return final_demos
    
    def adaptive_weight_learning(self, feedback_history):
        """ì„±ëŠ¥ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì ì‘"""
        # ê° ëª¨ë¸ì˜ ì„±ëŠ¥ ì¶”ì 
        model_performances = self.track_individual_performance(feedback_history)
        
        # ìƒí™©ë³„ ìµœì  ê°€ì¤‘ì¹˜ í•™ìŠµ
        context_weights = self.learn_context_specific_weights(
            feedback_history, model_performances
        )
        
        self.ensemble_weights = context_weights

# ê¸°ëŒ€ íš¨ê³¼:
# - ë‹¨ì¼ ëª¨ë¸ í•œê³„ ê·¹ë³µ
# - ë‹¤ì–‘í•œ ìƒí™©ì—ì„œ ì•ˆì •ì  ì„±ëŠ¥
# - ì‹¤íŒ¨ ì‚¬ë¡€ ìƒí˜¸ ë³´ì™„
```

#### Online Learning TopicK
```python
class OnlineTopicK(TopicK):
    """ì‚¬ìš©ì í”¼ë“œë°±ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        super().__init__()
        self.online_optimizer = OnlineGradientDescent()
        self.feedback_buffer = CircularBuffer(max_size=10000)
        self.performance_tracker = PerformanceTracker()
        
    def incremental_learning(self, query, selected_demos, user_feedback):
        # 1. í”¼ë“œë°±ì„ í•™ìŠµ ì‹ í˜¸ë¡œ ë³€í™˜
        training_signal = self.convert_feedback_to_signal(
            query, selected_demos, user_feedback
        )
        
        # 2. ì˜¨ë¼ì¸ í•™ìŠµìœ¼ë¡œ í† í”½ ì˜ˆì¸¡ê¸° ì—…ë°ì´íŠ¸
        self.online_optimizer.step(self.topic_predictor, training_signal)
        
        # 3. ì„±ëŠ¥ ì¶”ì  ë° ì´ìƒ íƒì§€
        current_performance = self.performance_tracker.update(
            query, selected_demos, user_feedback
        )
        
        if self.performance_tracker.detect_performance_drop():
            self.trigger_model_refresh()
        
        # 4. í”¼ë“œë°± ë²„í¼ì— ì €ì¥ (ì¶”í›„ ë°°ì¹˜ í•™ìŠµìš©)
        self.feedback_buffer.add((query, selected_demos, user_feedback))
    
    def continuous_improvement(self):
        """ì£¼ê¸°ì ìœ¼ë¡œ ëˆ„ì ëœ í”¼ë“œë°±ìœ¼ë¡œ ëª¨ë¸ ê°œì„ """
        if self.feedback_buffer.is_full():
            # ë°°ì¹˜ í•™ìŠµìœ¼ë¡œ ëŒ€í­ ê°œì„ 
            batch_data = self.feedback_buffer.get_all()
            improved_model = self.batch_retrain(batch_data)
            
            # A/B í…ŒìŠ¤íŠ¸ë¡œ ê°œì„  íš¨ê³¼ ê²€ì¦
            if self.ab_test(self.current_model, improved_model):
                self.current_model = improved_model
                self.feedback_buffer.clear()

# ì¥ì :
# - ì‹¤ì‹œê°„ ê°œì¸í™”
# - ì§€ì†ì  ì„±ëŠ¥ ê°œì„ 
# - ì‚¬ìš©ì í–‰ë™ íŒ¨í„´ í•™ìŠµ
# - ë°°í¬ í›„ì—ë„ ì§€ì† ë°œì „
```

## ğŸ¯ ê²°ë¡ 

TopicKì˜ ì°½ì˜ì  í™•ì¥ ê°€ëŠ¥ì„±ì€ ë¬´ê¶ë¬´ì§„í•©ë‹ˆë‹¤:

1. **ê¸°ìˆ ì  í˜ì‹ **: ê³„ì¸µì  í† í”½, ë‹¤ì¤‘ ëª¨ë‹¬, ì ëŒ€ì  ê°•ê±´ì„±
2. **ë„ë©”ì¸ íŠ¹í™”**: ì˜ë£Œ, ë²•ë¬´, êµìœ¡ ë“± ì „ë¬¸ ë¶„ì•¼ ìµœì í™”  
3. **ê°œì¸í™”**: í•™ìŠµ ìŠ¤íƒ€ì¼, ì§€ì‹ ìƒíƒœ ë§ì¶¤í˜• ì„œë¹„ìŠ¤
4. **ì‹œìŠ¤í…œ í†µí•©**: ê¸°ì—… ì§€ì‹ê´€ë¦¬, ì˜¨ë¼ì¸ í•™ìŠµ í”Œë«í¼
5. **ì„±ëŠ¥ ê·¹ëŒ€í™”**: ì•™ìƒë¸”, ì˜¨ë¼ì¸ í•™ìŠµ, ì ì‘í˜• ì‹œìŠ¤í…œ

ì´ëŸ¬í•œ í™•ì¥ë“¤ì€ TopicKë¥¼ ë‹¨ìˆœí•œ ë°ëª¨ ì„ íƒ ë„êµ¬ì—ì„œ **ì§€ëŠ¥í˜• ì§€ì‹ ê´€ë¦¬ í”Œë«í¼**ìœ¼ë¡œ ì§„í™”ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸš€